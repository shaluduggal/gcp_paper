{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaluduggal/gcp_paper/blob/machinelearning/brest_tumor_25_mar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xrIYqRtyYf6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653edcae-9f15-4cd3-9d38-29233928ffa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install visualkeras\n",
        "!pip install tensorflow\n",
        "!pip install keras-tuner"
      ],
      "id": "xrIYqRtyYf6l"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d5c42738"
      },
      "outputs": [],
      "source": [
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#import visualkeras\n",
        "from keras.utils import plot_model\n",
        "import math\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras_tuner import RandomSearch\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "from keras.layers import LeakyReLU,   Conv2D\n",
        "# CNN Architecture Visualization Library\n",
        "from keras.layers import Flatten,Dense,Dropout\n",
        "from keras import optimizers\n",
        "from keras.layers import BatchNormalization\n",
        "import keras_tuner\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from keras.layers import  MaxPool2D,MaxPooling2D, Activation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image ,ImageOps\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras import layers\n",
        "import tensorflow as tf"
      ],
      "id": "d5c42738"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "y_u5ODMvc6l8",
        "outputId": "43f39909-485a-428c-e693-a5570178355f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0c926de727e6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/dataset/benign'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#convert to grey scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "benign1 =[]\n",
        "frames= Path('/content/drive/MyDrive/dataset/benign')\n",
        "for file in frames.glob('*.png'):\n",
        "    img=Image.open(file)\n",
        "    img=ImageOps.grayscale(img)    #convert to grey scale\n",
        "    img=img.resize((224,224))\n",
        "    #we can use img.thumnail () to resize so that aspect ratio is maintained\n",
        "  #  img.save('D:/research_p/dataset/benign'+file+\".jpg\")\n",
        "    benign1.append(np.array(img))\n",
        "b =len(benign1)\n",
        "malignant1 =[]\n",
        "frames= Path('/content/drive/MyDrive/dataset/malignant')\n",
        "for file in frames.glob('*.png'):\n",
        "    img=Image.open(file)\n",
        "    img=ImageOps.grayscale(img)    #convert to grey scale\n",
        "    img=img.resize((224,224))\n",
        "   # img.save('D:/research_p/dataset/malignant')\n",
        "    malignant1.append(np.array(img))\n",
        "m =len(malignant1)\n",
        "normal1 =[]\n",
        "frames= Path('/content/drive/MyDrive/dataset/normal')\n",
        "for file in frames.glob('*.png'):\n",
        "    img=Image.open(file)\n",
        "    img=ImageOps.grayscale(img)     #convert to grey scale\n",
        "    img=img.resize((224,224))\n",
        "    #img.save('D:/research_p/dataset/normal')\n",
        "    normal1.append(np.array(img))\n",
        "n =len(normal1)\n",
        "print(n)"
      ],
      "id": "y_u5ODMvc6l8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7316af9"
      },
      "outputs": [],
      "source": [
        "#Features combination\n",
        "#combining data into images\n",
        "images =[ ]\n",
        "images.extend(malignant1)\n",
        "images.extend(benign1)\n",
        "images.extend(normal1)\n",
        "#en(images)\n",
        "#images[203].shape\n",
        "#adding labels\n",
        "labels=[ ]\n",
        "m=[1]*m\n",
        "b=[2]*b\n",
        "n=[0]*n\n",
        "labels.extend(m)\n",
        "labels.extend(b)\n",
        "labels.extend(n)\n",
        "len(labels)\n",
        "print(len(b)+len(m)+len(n))"
      ],
      "id": "a7316af9"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "fc120668",
        "outputId": "26da5d16-3d14-44c2-f21f-8b3a60e30089"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6ce713127300>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ],
      "source": [
        "def normalize(x):\n",
        "    min_val = np.min(x)\n",
        "    max_val = np.max(x)\n",
        "    x = (x-min_val) / (max_val-min_val)\n",
        "    return x\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test =train_test_split(images,labels,test_size=0.2,random_state=41)\n",
        "x_train=np.array(x_train)\n",
        "x_test=np.array(x_test)\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)\n",
        "#x_train = normalize(x_train)\n",
        "#x_test = normalize(x_test)\n",
        "x_train=x_train.reshape((624,224,224,1))\n",
        "x_test=x_test.reshape((156,224,224,1))\n",
        "y_train = keras.utils.to_categorical(y_train,num_classes=3)\n",
        "y_test = keras.utils.to_categorical(y_test,num_classes=3)\n",
        "\n",
        "#print(x_train.shape)\n",
        "#print(x_test.shape)\n",
        "#input_shape1=(x_test[0].shape)\n",
        "#print(input_shape1)\n",
        "#print(y_train.shape,y_test[0].shape)"
      ],
      "id": "fc120668"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4cda701"
      },
      "outputs": [],
      "source": [
        "#basic model1\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "#model.add(layers.Dropout(rate=0.3))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "checkpoint_path = \"/bin/chk_point1\"\n",
        "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = [EarlyStopping(monitor='val_loss', patience=2),\n",
        "              keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)]\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test),callbacks=[cp_callback])"
      ],
      "id": "f4cda701"
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the about model 1 trained parameters\n",
        "import pickle\n",
        "\n",
        "# save the iris classification model a_s a pickle file\n",
        "model_pkl_file1 = \"First_trained_model_25-03-2024\"\n",
        "\n",
        "with open(model_pkl_file1, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "#with open(model_pkl_file1, 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# evaluate model\n",
        "#y_predict = model.predict(x_test)\n",
        "\n",
        "# check results\n",
        "#print(classification_report(y_test, y_predict))\n",
        "#"
      ],
      "metadata": {
        "id": "b2AUDjh_vZw-"
      },
      "id": "b2AUDjh_vZw-",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s6RWwFxwHa-",
        "outputId": "3436b5e6-114b-43c1-d07f-1402e473d610"
      },
      "id": "7s6RWwFxwHa-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 5s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4wDVWG2fP2z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(\"output_report.png\")"
      ],
      "id": "z4wDVWG2fP2z"
    },
    {
      "cell_type": "code",
      "source": [
        "#model2\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='tanh'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='tanh'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dense(128, activation='tanh'))\n",
        "#model.add(layers.Dropout(rate=0.3))\n",
        "model.add(layers.Dense(64, activation='tanh'))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "checkpoint_path = \"/bin/chk_point1_25_mar\"\n",
        "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = [EarlyStopping(monitor='val_loss', patience=2),\n",
        "              keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)]\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test),callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "_vXYI7xz5TqL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "61e13973-f853-4d25-c367-2b67163226fc"
      },
      "id": "_vXYI7xz5TqL",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Sequential' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0818573418da>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper tuning optimizer, model2 for activation tanh\n",
        "#optimizing optimizer\n",
        "def build_model(hp):  # random search passes this hyperparameter() object\n",
        "  model= Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(3,activation=\"softmax\"))\n",
        "  model.summary()\n",
        "  optimizer=hp.Choice(\"otimizers\",values=[\"adam\",\"rmsprop\",\"sgd\",\"adadelta\"])\n",
        "  model.compile(optimizer=optimizer,  metrics=['accuracy'], loss=\"sparse_categorical_crossentropy\")\n",
        "  return model\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # how many model variations to test?\n",
        "    executions_per_trial=3,  # how many trials per variation? (same model could perform differently)\n",
        "    directory=\"/bin/dir_1/optimizer_model_data\",\n",
        "    project_name='breast_tumor_paper1'\n",
        ")\n",
        "tuner.search(x_train,y_train,epochs=2,validation_data=(x_test,y_test))\n",
        "print(tuner.get_best_hyperparameters()[0].values)\n",
        "model=tuner.get_best_models(num_models=1)[0]\n",
        "model.summary()\n",
        "model.fit(x_train,y_train,batch_size=32,epochs=25,initial_epoch=6,validation_data=(x_test,y_test))\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
        "# save the iris classification model as a pickle file\n",
        "import pickle\n",
        "model_pkl_file2 = \"Seconf_trained_model_25_mar\"\n",
        "with open(model_pkl_file2, 'wb') as file:\n",
        "    pickle.dump(model, file)\n"
      ],
      "metadata": {
        "id": "YOc0r2GyOsxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "158ff74e-5994-4b23-b116-065dbfba960f"
      },
      "id": "YOc0r2GyOsxR",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'RandomSearch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c5a7f7e83636>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m tuner = RandomSearch(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomSearch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model 3 with keras tuner activation relu\n",
        "def build_model(hp):  # random search passes this hyperparameter() object\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(Conv2D(\n",
        "           filters=hp.Int('conv_filters_layer1',min_value=32,max_value=128,step=16),\n",
        "           kernel_size=hp.Choice('conv_kernel_layer1',values=[3,4]),\n",
        "           input_shape=(224,224,1)\n",
        "    ))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  for i in range(hp.Int('n_layers', 1, 4)):  # adding variation of layers.\n",
        "        model.add(Conv2D(hp.Int(f'conv_{i}_units',\n",
        "                                min_value=32,\n",
        "                                max_value=256,\n",
        "                                step=32), (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  for i in range(hp.Int('n_connections', 1, 4)):\n",
        "        model.add(Dense(hp.Choice(f'n_nodes',values=[128, 256, 512])))\n",
        "        model.add(Activation('relu'))\n",
        "  if hp.Boolean(name=\"dropout\"):\n",
        "      model.add(Dropout(rate=0.5))\n",
        "  model.add(Dense(3))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  model.compile(optimizer=\"adam\",\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "vQtkdwI_eXcY"
      },
      "id": "vQtkdwI_eXcY",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # how many model variations to test?\n",
        "    executions_per_trial=3,  # how many trials per variation? (same model could perform differently)\n",
        "    directory=\"/bin/dir_1/optimizer_model_data\",\n",
        "    project_name='breast_tumor_paper1'\n",
        ")\n",
        "tuner.search(x_train,y_train,epochs=2,validation_data=(x_test,y_test))\n",
        "print(tuner.get_best_hyperparameters()[0].values)\n",
        "model=tuner.get_best_models(num_models=1)[0]\n",
        "model.summary()\n",
        "model.fit(x_train,y_train,batch_size=32,epochs=25,initial_epoch=6,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "id": "w_E2Tkbgm3dR"
      },
      "id": "w_E2Tkbgm3dR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "# save the iris classification model as a pickle file\n",
        "model_pkl_file2 = \"third_ optimzer_trained_model_25_mar\"\n",
        "with open(model_pkl_file2, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "Z4ECMGlfzf-j"
      },
      "id": "Z4ECMGlfzf-j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "print(best_hps)"
      ],
      "metadata": {
        "id": "4Kxsb-F6OtNX"
      },
      "id": "4Kxsb-F6OtNX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3gB_Ch64pzZ"
      },
      "source": [],
      "id": "G3gB_Ch64pzZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e2ac120"
      },
      "source": [
        "# Hyperparameter tuning"
      ],
      "id": "2e2ac120"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}